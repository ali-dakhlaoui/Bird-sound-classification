{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65176,
     "status": "ok",
     "timestamp": 1668590899989,
     "user": {
      "displayName": "Zeineb Ghorbel",
      "userId": "11322648816756691679"
     },
     "user_tz": -60
    },
    "id": "Fdaoqg1_LJtg",
    "outputId": "2722994e-7658-4f87-f555-10d570715fce"
   },
   "outputs": [],
   "source": [
    "# # upload your kaggle.json file \n",
    "# !pip install kaggle\n",
    "# # !mkdir /root/.kaggle\n",
    "# # ! mkdir ~/.kaggle\n",
    "# ! cp kaggle.json ~/.kaggle\n",
    "# ! chmod 600 ~/.kaggle/kaggle.json\n",
    "# # !cp kaggle.json /root/.kaggle\n",
    "# #command to get data from kaggle \n",
    "# !kaggle competitions download -c birdclef-2022\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4373,
     "status": "ok",
     "timestamp": 1668590904349,
     "user": {
      "displayName": "Zeineb Ghorbel",
      "userId": "11322648816756691679"
     },
     "user_tz": -60
    },
    "id": "xrkrGy0iLXfu",
    "outputId": "10768c27-fae9-435b-e095-f0271ea3f951"
   },
   "outputs": [],
   "source": [
    "# !pip install torchlibrosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 97692,
     "status": "ok",
     "timestamp": 1668591002027,
     "user": {
      "displayName": "Zeineb Ghorbel",
      "userId": "11322648816756691679"
     },
     "user_tz": -60
    },
    "id": "pIqWMkZhLLc8"
   },
   "outputs": [],
   "source": [
    "# !unzip -qq birdclef-2022.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7732,
     "status": "ok",
     "timestamp": 1668591183720,
     "user": {
      "displayName": "Zeineb Ghorbel",
      "userId": "11322648816756691679"
     },
     "user_tz": -60
    },
    "id": "fG8dmc4ILMfx"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import audioread\n",
    "import logging\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "# sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "# import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as torchdata\n",
    "\n",
    "from contextlib import contextmanager\n",
    "from joblib import Parallel, delayed\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "\n",
    "# from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "from torchlibrosa.stft import LogmelFilterBank, Spectrogram\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import albumentations as A\n",
    "# import albumentations.pytorch.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import efficientnet.tfkeras as efn  # Convolutional Neural Network architecture\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# from efficientnet.keras import preprocess_input\n",
    "# from keras.callbacks.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "# from sklearn.utils import class_weight\n",
    "# from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchlibrosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1668591644084,
     "user": {
      "displayName": "Zeineb Ghorbel",
      "userId": "11322648816756691679"
     },
     "user_tz": -60
    },
    "id": "gH6y9bDxz-C3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1668591766178,
     "user": {
      "displayName": "Zeineb Ghorbel",
      "userId": "11322648816756691679"
     },
     "user_tz": -60
    },
    "id": "MHgLWmTRz0If"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Data:\n",
    "TRAIN_DIR = './train_audio/'\n",
    "IMAGES_DIR = './imageeees/'\n",
    "SAMPLE_RATE = 32000\n",
    "VAL_SIZE = 0.2\n",
    "\n",
    "# Data processing:\n",
    "N_FFT = 2048\n",
    "HOP_LEN = 512\n",
    "WIN_FUNC = 'hann'\n",
    "N_MELS = 224\n",
    "F_MIN = 0\n",
    "F_MAX = SAMPLE_RATE / 2\n",
    "\n",
    "# Learning process:\n",
    "NAME_MODEL_0 = \"model_0_inst.h5\"\n",
    "NAME_MODEL_0_PIC = 'model_0_pic.png'\n",
    "NAME_MODEL_0_CHECKPOINT = 'model_0_cp.ckpt'\n",
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_WIDTH = 256\n",
    "BATCH_SIZE = 32\n",
    "N_CHANNELS = 3\n",
    "EPOCHS = 5\n",
    "CALL_BACKS = [tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=NAME_MODEL_0_CHECKPOINT,\n",
    "    save_weights_only=True,\n",
    "    verbose=0\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1668591768175,
     "user": {
      "displayName": "Zeineb Ghorbel",
      "userId": "11322648816756691679"
     },
     "user_tz": -60
    },
    "id": "5eZp3nprz3Nq",
    "outputId": "d453168b-ceae-4832-f45a-e80ff36f41c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_label</th>\n",
       "      <th>secondary_labels</th>\n",
       "      <th>type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>scientific_name</th>\n",
       "      <th>common_name</th>\n",
       "      <th>author</th>\n",
       "      <th>license</th>\n",
       "      <th>rating</th>\n",
       "      <th>time</th>\n",
       "      <th>url</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afrsil1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['call', 'flight call']</td>\n",
       "      <td>12.3910</td>\n",
       "      <td>-1.4930</td>\n",
       "      <td>Euodice cantans</td>\n",
       "      <td>African Silverbill</td>\n",
       "      <td>Bram Piot</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>08:00</td>\n",
       "      <td>https://www.xeno-canto.org/125458</td>\n",
       "      <td>afrsil1/XC125458.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afrsil1</td>\n",
       "      <td>['houspa', 'redava', 'zebdov']</td>\n",
       "      <td>['call']</td>\n",
       "      <td>19.8801</td>\n",
       "      <td>-155.7254</td>\n",
       "      <td>Euodice cantans</td>\n",
       "      <td>African Silverbill</td>\n",
       "      <td>Dan Lane</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>08:30</td>\n",
       "      <td>https://www.xeno-canto.org/175522</td>\n",
       "      <td>afrsil1/XC175522.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afrsil1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['call', 'song']</td>\n",
       "      <td>16.2901</td>\n",
       "      <td>-16.0321</td>\n",
       "      <td>Euodice cantans</td>\n",
       "      <td>African Silverbill</td>\n",
       "      <td>Bram Piot</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11:30</td>\n",
       "      <td>https://www.xeno-canto.org/177993</td>\n",
       "      <td>afrsil1/XC177993.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afrsil1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['alarm call', 'call']</td>\n",
       "      <td>17.0922</td>\n",
       "      <td>54.2958</td>\n",
       "      <td>Euodice cantans</td>\n",
       "      <td>African Silverbill</td>\n",
       "      <td>Oscar Campbell</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11:00</td>\n",
       "      <td>https://www.xeno-canto.org/205893</td>\n",
       "      <td>afrsil1/XC205893.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afrsil1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['flight call']</td>\n",
       "      <td>21.4581</td>\n",
       "      <td>-157.7252</td>\n",
       "      <td>Euodice cantans</td>\n",
       "      <td>African Silverbill</td>\n",
       "      <td>Ross Gallardy</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16:30</td>\n",
       "      <td>https://www.xeno-canto.org/207431</td>\n",
       "      <td>afrsil1/XC207431.ogg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  primary_label                secondary_labels                     type  \\\n",
       "0       afrsil1                              []  ['call', 'flight call']   \n",
       "1       afrsil1  ['houspa', 'redava', 'zebdov']                 ['call']   \n",
       "2       afrsil1                              []         ['call', 'song']   \n",
       "3       afrsil1                              []   ['alarm call', 'call']   \n",
       "4       afrsil1                              []          ['flight call']   \n",
       "\n",
       "   latitude  longitude  scientific_name         common_name          author  \\\n",
       "0   12.3910    -1.4930  Euodice cantans  African Silverbill       Bram Piot   \n",
       "1   19.8801  -155.7254  Euodice cantans  African Silverbill        Dan Lane   \n",
       "2   16.2901   -16.0321  Euodice cantans  African Silverbill       Bram Piot   \n",
       "3   17.0922    54.2958  Euodice cantans  African Silverbill  Oscar Campbell   \n",
       "4   21.4581  -157.7252  Euodice cantans  African Silverbill   Ross Gallardy   \n",
       "\n",
       "                                             license  rating   time  \\\n",
       "0  Creative Commons Attribution-NonCommercial-Sha...     2.5  08:00   \n",
       "1  Creative Commons Attribution-NonCommercial-Sha...     3.5  08:30   \n",
       "2  Creative Commons Attribution-NonCommercial-Sha...     4.0  11:30   \n",
       "3  Creative Commons Attribution-NonCommercial-Sha...     4.0  11:00   \n",
       "4  Creative Commons Attribution-NonCommercial-Sha...     3.0  16:30   \n",
       "\n",
       "                                 url              filename  \n",
       "0  https://www.xeno-canto.org/125458  afrsil1/XC125458.ogg  \n",
       "1  https://www.xeno-canto.org/175522  afrsil1/XC175522.ogg  \n",
       "2  https://www.xeno-canto.org/177993  afrsil1/XC177993.ogg  \n",
       "3  https://www.xeno-canto.org/205893  afrsil1/XC205893.ogg  \n",
       "4  https://www.xeno-canto.org/207431  afrsil1/XC207431.ogg  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_metadata = pd.read_csv('./train_metadata.csv')\n",
    "train_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1668591768407,
     "user": {
      "displayName": "Zeineb Ghorbel",
      "userId": "11322648816756691679"
     },
     "user_tz": -60
    },
    "id": "hLPeF0mFzg6q"
   },
   "outputs": [],
   "source": [
    "# Load work classes:\n",
    "with open('./scored_birds.json', 'r') as f:\n",
    "    valid_classes = json.load(f)\n",
    "\n",
    "primary_labels = train_metadata.primary_label\n",
    "\n",
    "# Encode labels:\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "labels = encoder.fit_transform(primary_labels)\n",
    "labels = np.uint8(labels)\n",
    "\n",
    "NUM_CLASSES = len(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_reduction(y, sr, plot=True, th=0.3):\n",
    "    from scipy.fft import fft, fftfreq, ifft\n",
    "    \n",
    "    SAMPLE_RATE = 1\n",
    "    DURATION = len(y) / SAMPLE_RATE\n",
    "    N = int(SAMPLE_RATE * DURATION)\n",
    "\n",
    "    yf = fft(y)\n",
    "    xf = fftfreq(N, 1 / SAMPLE_RATE)\n",
    "    \n",
    "    if plot:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(24, 8))\n",
    "        axes[0].plot(np.arange(len(y)), y)\n",
    "        axes[0].set_title('Before Time-Domain')\n",
    "        axes[1].plot(xf, np.abs(yf))\n",
    "        axes[1].set_title('Before Frequency-Domain')\n",
    "        plt.show()\n",
    "    \n",
    "    # Filtering Low-Pass\n",
    "    new_yf = yf.copy()\n",
    "    middle = len(y) / 2\n",
    "    new_yf[int(middle - len(y) * th):int(middle + len(y) * th)] = 0\n",
    "    new_y = ifft(new_yf)\n",
    "    new_y = new_y.real\n",
    "    \n",
    "    if plot:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(24, 8))\n",
    "        axes[0].plot(np.arange(len(y)), new_y)\n",
    "        axes[0].set_title('After Time-Domain')\n",
    "        axes[1].plot(xf, np.abs(new_yf))\n",
    "        axes[1].set_title('After Frequency-Domain')\n",
    "        plt.show()\n",
    "    \n",
    "    return new_y, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14852, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "      <th>len</th>\n",
       "      <th>label</th>\n",
       "      <th>peaks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_audio/oahama/XC511591.ogg</td>\n",
       "      <td>612864</td>\n",
       "      <td>oahama</td>\n",
       "      <td>4.224#16.06#5.072#3.280#1.248#9.040#17.74#12.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_audio/oahama/XC27358.ogg</td>\n",
       "      <td>152137</td>\n",
       "      <td>oahama</td>\n",
       "      <td>2.801#0.512#0.512#0.512#0.512#0.512#0.512#0.51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_audio/oahama/XC454888.ogg</td>\n",
       "      <td>2002860</td>\n",
       "      <td>oahama</td>\n",
       "      <td>41.86#41.04#33.09#19.14#37.57#1.552#27.06#2.36...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                fn      len   label  \\\n",
       "0  train_audio/oahama/XC511591.ogg   612864  oahama   \n",
       "1   train_audio/oahama/XC27358.ogg   152137  oahama   \n",
       "2  train_audio/oahama/XC454888.ogg  2002860  oahama   \n",
       "\n",
       "                                               peaks  \n",
       "0  4.224#16.06#5.072#3.280#1.248#9.040#17.74#12.8...  \n",
       "1  2.801#0.512#0.512#0.512#0.512#0.512#0.512#0.51...  \n",
       "2  41.86#41.04#33.09#19.14#37.57#1.552#27.06#2.36...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_info = pd.read_csv('info_df.csv')\n",
    "print(df_info.shape)\n",
    "df_info.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1668591768408,
     "user": {
      "displayName": "Zeineb Ghorbel",
      "userId": "11322648816756691679"
     },
     "user_tz": -60
    },
    "id": "epd9bsnFLMh_"
   },
   "outputs": [],
   "source": [
    "# Load audio:\n",
    "def loadAudio(filename: str) -> np.ndarray:\n",
    "    # Load audio:\n",
    "    signal, sr = librosa.load(\n",
    "        filename,\n",
    "        sr=SAMPLE_RATE,\n",
    "        mono=True,\n",
    "        dtype=np.float32)\n",
    "    new_y, sr = noise_reduction(signal, sr, plot=False, th=0.3)\n",
    "\n",
    "    \n",
    "    \n",
    "    return new_y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert audio frame into spectrogram:\n",
    "def createSpectrogram(frame: np.ndarray) -> np.ndarray:\n",
    "    specgram = librosa.feature.melspectrogram(\n",
    "        y=frame,\n",
    "        sr=SAMPLE_RATE,\n",
    "        n_fft=N_FFT,\n",
    "        hop_length=HOP_LEN,\n",
    "        win_length=N_FFT,\n",
    "        window='hann',\n",
    "        center=True,\n",
    "        pad_mode='reflect',\n",
    "        power=2.0,\n",
    "        n_mels=N_MELS,\n",
    "        fmin=F_MIN,\n",
    "        fmax=F_MAX,\n",
    "        dtype=np.float32\n",
    "    )\n",
    "    specgram = librosa.amplitude_to_db(specgram, ref=np.max)\n",
    "    \n",
    "    return specgram\n",
    "\n",
    "\n",
    "# Save spectrogram as png:\n",
    "def saveSpectogram(specgram: np.ndarray, filename: str, label: np.uint8, ind: int) -> None:\n",
    "    bird_name = filename.rsplit('/', 2)[0]\n",
    "    file_id = filename.rsplit('/', 2)[1].rsplit('.', 2)[0]\n",
    "    file_name = IMAGES_DIR + 'class_' + str(labels[i]) + '/' + bird_name + '_' + file_id + '_' + str((ind + 1) * 5) + '.png'\n",
    "    specgram = specgram + 80 # -80 dB -> Min\n",
    "    specgram = specgram.astype(np.uint8) # 0 - 255 the pixel value\n",
    "    plt.axis('off')\n",
    "    plt.imsave(file_name, specgram)\n",
    "    \n",
    "\n",
    "# Common function:\n",
    "def convertAudio(filename: str, label: np.uint8) -> None:\n",
    "    signal = loadAudio(filename=TRAIN_DIR + filename)\n",
    "    frames = framing(\n",
    "        sig=signal,\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        frame_len=5,\n",
    "        duration_time=librosa.get_duration(\n",
    "            y=signal,\n",
    "            sr=SAMPLE_RATE)\n",
    "    )\n",
    "    for i in range(frames.shape[0]):\n",
    "        specgram = createSpectrogram(frame=frames[i])\n",
    "        saveSpectogram(\n",
    "            specgram=specgram,\n",
    "            filename=filename,\n",
    "            label=label,\n",
    "            ind=i\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1038,
     "status": "ok",
     "timestamp": 1668591869223,
     "user": {
      "displayName": "Zeineb Ghorbel",
      "userId": "11322648816756691679"
     },
     "user_tz": -60
    },
    "id": "OpYUN0rZ0ld7"
   },
   "outputs": [],
   "source": [
    "!rm -rf  \"./imageeees\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 13241709,
     "status": "ok",
     "timestamp": 1668605115207,
     "user": {
      "displayName": "Zeineb Ghorbel",
      "userId": "11322648816756691679"
     },
     "user_tz": -60
    },
    "id": "vVXdUk7lLMkB",
    "outputId": "88d9a594-6604-4ec8-f789-f4ebc265f967"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14852 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ParameterError",
     "evalue": "Audio data must be of type numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParameterError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [75]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Convert audio into spectragrams:\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(train_metadata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])):\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mconvertAudio\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_metadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36mconvertAudio\u001b[0;34m(filename, label)\u001b[0m\n\u001b[1;32m     71\u001b[0m frames \u001b[38;5;241m=\u001b[39m framing(\n\u001b[1;32m     72\u001b[0m     sig\u001b[38;5;241m=\u001b[39msignal,\n\u001b[1;32m     73\u001b[0m     sample_rate\u001b[38;5;241m=\u001b[39mSAMPLE_RATE,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m         sr\u001b[38;5;241m=\u001b[39mSAMPLE_RATE)\n\u001b[1;32m     78\u001b[0m )\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(frames\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m---> 80\u001b[0m     specgram \u001b[38;5;241m=\u001b[39m \u001b[43mcreateSpectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     saveSpectogram(\n\u001b[1;32m     82\u001b[0m         specgram\u001b[38;5;241m=\u001b[39mspecgram,\n\u001b[1;32m     83\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m     84\u001b[0m         label\u001b[38;5;241m=\u001b[39mlabel,\n\u001b[1;32m     85\u001b[0m         ind\u001b[38;5;241m=\u001b[39mi\n\u001b[1;32m     86\u001b[0m     )\n",
      "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36mcreateSpectrogram\u001b[0;34m(frame)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreateSpectrogram\u001b[39m(frame: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m---> 37\u001b[0m     specgram \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmelspectrogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSAMPLE_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_FFT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHOP_LEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_FFT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhann\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreflect\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_mels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_MELS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mF_MIN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mF_MAX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     specgram \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mamplitude_to_db(specgram, ref\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m specgram\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/librosa/util/decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     91\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[1;32m     94\u001b[0m ]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/librosa/feature/spectral.py:2043\u001b[0m, in \u001b[0;36mmelspectrogram\u001b[0;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;129m@deprecate_positional_args\u001b[39m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmelspectrogram\u001b[39m(\n\u001b[1;32m   1924\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1935\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1936\u001b[0m ):\n\u001b[1;32m   1937\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute a mel-scaled spectrogram.\u001b[39;00m\n\u001b[1;32m   1938\u001b[0m \n\u001b[1;32m   1939\u001b[0m \u001b[38;5;124;03m    If a spectrogram input ``S`` is provided, then it is mapped directly onto\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2040\u001b[0m \u001b[38;5;124;03m    >>> ax.set(title='Mel-frequency spectrogram')\u001b[39;00m\n\u001b[1;32m   2041\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2043\u001b[0m     S, n_fft \u001b[38;5;241m=\u001b[39m \u001b[43m_spectrogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2044\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpower\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2055\u001b[0m     \u001b[38;5;66;03m# Build a Mel filter\u001b[39;00m\n\u001b[1;32m   2056\u001b[0m     mel_basis \u001b[38;5;241m=\u001b[39m filters\u001b[38;5;241m.\u001b[39mmel(sr\u001b[38;5;241m=\u001b[39msr, n_fft\u001b[38;5;241m=\u001b[39mn_fft, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/librosa/core/spectrum.py:2564\u001b[0m, in \u001b[0;36m_spectrogram\u001b[0;34m(y, S, n_fft, hop_length, power, win_length, window, center, pad_mode)\u001b[0m\n\u001b[1;32m   2559\u001b[0m         n_fft \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (S\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2560\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2561\u001b[0m     \u001b[38;5;66;03m# Otherwise, compute a magnitude spectrogram from input\u001b[39;00m\n\u001b[1;32m   2562\u001b[0m     S \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2563\u001b[0m         np\u001b[38;5;241m.\u001b[39mabs(\n\u001b[0;32m-> 2564\u001b[0m             \u001b[43mstft\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2565\u001b[0m \u001b[43m                \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2566\u001b[0m \u001b[43m                \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2567\u001b[0m \u001b[43m                \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2568\u001b[0m \u001b[43m                \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2569\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2570\u001b[0m \u001b[43m                \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2571\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2572\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2573\u001b[0m         )\n\u001b[1;32m   2574\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m power\n\u001b[1;32m   2575\u001b[0m     )\n\u001b[1;32m   2577\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m S, n_fft\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/librosa/util/decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     91\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[1;32m     94\u001b[0m ]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/librosa/core/spectrum.py:202\u001b[0m, in \u001b[0;36mstft\u001b[0;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode)\u001b[0m\n\u001b[1;32m    199\u001b[0m     hop_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(win_length \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m# Check audio is valid\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmono\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m fft_window \u001b[38;5;241m=\u001b[39m get_window(window, win_length, fftbins\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    206\u001b[0m \u001b[38;5;66;03m# Pad the window out to n_fft size\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/librosa/util/decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     91\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[1;32m     94\u001b[0m ]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/librosa/util/utils.py:272\u001b[0m, in \u001b[0;36mvalid_audio\u001b[0;34m(y, mono)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m\"\"\"Determine whether a variable contains valid audio data.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03mThe following conditions must be satisfied:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03mnumpy.float32\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m--> 272\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAudio data must be of type numpy.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(y\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloating):\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAudio data must be floating-point\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mParameterError\u001b[0m: Audio data must be of type numpy.ndarray"
     ]
    }
   ],
   "source": [
    "# Create dirs for each class:\n",
    "os.mkdir(IMAGES_DIR)\n",
    "for i in range(np.unique(labels).shape[0]):\n",
    "    os.mkdir(IMAGES_DIR + 'class_' + str(np.unique(labels)[i]) + '/')\n",
    "    \n",
    "# Convert audio into spectragrams:\n",
    "for i in tqdm(range(train_metadata.shape[0])):\n",
    "    convertAudio(\n",
    "        filename=train_metadata.filename.iloc[i],\n",
    "        label=labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17024,
     "status": "ok",
     "timestamp": 1668605132226,
     "user": {
      "displayName": "Zeineb Ghorbel",
      "userId": "11322648816756691679"
     },
     "user_tz": -60
    },
    "id": "DZCJZfYPLMl3",
    "outputId": "da009800-6c13-4f25-d9b0-39cd4756d4c4"
   },
   "outputs": [],
   "source": [
    "# Make a dataset containing the training spectrograms\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VAL_SIZE,\n",
    "    directory=IMAGES_DIR,\n",
    "    shuffle=True,\n",
    "    color_mode='rgb',\n",
    "    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    subset=\"training\",\n",
    "    label_mode='categorical',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Make a dataset containing the validation spectrogram\n",
    "valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VAL_SIZE,\n",
    "    directory=IMAGES_DIR,\n",
    "    shuffle=True,\n",
    "    color_mode='rgb',\n",
    "    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    subset=\"validation\",\n",
    "    label_mode='categorical',\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1668605132227,
     "user": {
      "displayName": "Zeineb Ghorbel",
      "userId": "11322648816756691679"
     },
     "user_tz": -60
    },
    "id": "8X3e_6omLMn4"
   },
   "outputs": [],
   "source": [
    "# Function to prepare our datasets for modelling\n",
    "def prepare(ds, augment=False):\n",
    "    # Define our one transformation\n",
    "    rescale = tf.keras.Sequential([tf.keras.layers.experimental.preprocessing.Rescaling(1./255)])\n",
    "    flip_and_rotate = tf.keras.Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)\n",
    "    ])\n",
    "    \n",
    "    # Apply rescale to both datasets and augmentation only to training\n",
    "    ds = ds.map(lambda x, y: (rescale(x, training=True), y))\n",
    "    if augment: ds = ds.map(lambda x, y: (flip_and_rotate(x, training=True), y))\n",
    "    return ds\n",
    "\n",
    "train_dataset = prepare(train_dataset, augment=False)\n",
    "valid_dataset = prepare(valid_dataset, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2294,
     "status": "ok",
     "timestamp": 1668605134507,
     "user": {
      "displayName": "Zeineb Ghorbel",
      "userId": "11322648816756691679"
     },
     "user_tz": -60
    },
    "id": "cpM7uvG8LMqI"
   },
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    # Create CNN model\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, N_CHANNELS)))\n",
    "    model.add(tf.keras.layers.Conv2D(32, 3, strides=2, padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(np.unique(labels).shape[0], activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.RMSprop(),\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.Recall()\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def plotMetrics(history):\n",
    "    metrics = list()\n",
    "    for key, value in history.history.items():\n",
    "        metrics.append(key)\n",
    "        \n",
    "    for i in range(int(len(metrics) / 2)):\n",
    "        plt.figure(figsize=(24, 6))\n",
    "        plt.plot(history.history[metrics[i]], c =\"darkblue\")\n",
    "        plt.plot(history.history[metrics[i + int(len(metrics) / 2)]], c =\"crimson\")\n",
    "        plt.legend([\"Train\", \"Validation\"])\n",
    "        plt.title(\"Model\" + metrics[i])\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(metrics[i])\n",
    "        plt.grid(True, alpha = 0.2)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZ1q0H7tLMsE"
   },
   "outputs": [],
   "source": [
    "model = getModel()\n",
    "tf.keras.utils.plot_model(model, NAME_MODEL_0_PIC, show_shapes=True)\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=valid_dataset,\n",
    "    callbacks=CALL_BACKS\n",
    ")\n",
    "model.save(NAME_MODEL_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDzxal94LMuM"
   },
   "outputs": [],
   "source": [
    "plotMetrics(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "aborted",
     "timestamp": 1668591002034,
     "user": {
      "displayName": "Zeineb Ghorbel",
      "userId": "11322648816756691679"
     },
     "user_tz": -60
    },
    "id": "trWKFHJ_LMvq"
   },
   "outputs": [],
   "source": [
    "pred = {\n",
    "    'row_id': list(),\n",
    "    'target': list()\n",
    "}\n",
    "\n",
    "test_path = './test_soundscapes/'\n",
    "files = [f.split('.')[0] for f in sorted(os.listdir(test_path))]\n",
    "\n",
    "birds_path = './scored_birds.json'\n",
    "with open(birds_path) as bf:\n",
    "    birds = json.load(bf)\n",
    "    \n",
    "for f in files:\n",
    "    p = test_path + f + '.ogg'\n",
    "    \n",
    "    sig = loadAudio(filename=p)\n",
    "    duration_sig = librosa.get_duration(y=sig, sr=SAMPLE_RATE)\n",
    "    sig_framed = framing(sig=sig, sample_rate=SAMPLE_RATE, frame_len=5, duration_time=duration_sig)\n",
    "    \n",
    "    for i in range(sig_framed.shape[0]):\n",
    "        # Get prediction:\n",
    "        specgram = createSpectrogram(frame=sig_framed[i])\n",
    "        specgram = specgram + 80 # -80 dB -> Min\n",
    "        specgram = specgram.astype(np.uint8) # 0 - 255 the pixel value\n",
    "\n",
    "        y_pred = model.predict(specgram)\n",
    "        predicted_class = np.argmax(y_pred)\n",
    "\n",
    "        for b in birds:  \n",
    "            segment_end = (i + 1) * 5\n",
    "            row_id = f + '_' + b + '_' + str(segment_end)\n",
    "            pred['row_id'].append(row_id)\n",
    "            label_inv = encoder.inverse_transform([predicted_class])\n",
    "            if label_inv[0] == b:\n",
    "                pred['target'].append(True)\n",
    "            else:\n",
    "                pred['target'].append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "aborted",
     "timestamp": 1668591002034,
     "user": {
      "displayName": "Zeineb Ghorbel",
      "userId": "11322648816756691679"
     },
     "user_tz": -60
    },
    "id": "bBYhpHegLMyH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "aborted",
     "timestamp": 1668591002035,
     "user": {
      "displayName": "Zeineb Ghorbel",
      "userId": "11322648816756691679"
     },
     "user_tz": -60
    },
    "id": "Ust9kZcCLMz5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMnelWAymL5QHrAZOWwF0U+",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
